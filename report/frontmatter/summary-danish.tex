%!TEX root = ../Thesis.tex
\chapter{Summary (Danish)}

Denne afhandling undersøger modeller til at oversætte imellem naturlige sprog. Modellerne er baseret på en fornyligt publiceret model kaldet ByteNet. ByteNet modellen er en ny tilgang til neural maskine oversættelse, som ikke er baseret på \textit{attention}, men istedet bruger lag af \textit{hierarchical dilated convolutions}. Ved brug af denne metode kan ByteNet kører i lineær tid og samtidig have en opløsning, der er proportionel med sætningslængden.

Ved at bruge en variation af ByteNet modellen er modellen benyttet i en semi-vejledt kontekst, hvor den er trænet på både et tosproget og ensproget datasæt. Iden er at de bedste ydende modeller er dem, som bruger mest data, for sprogpar hvor det tosproget dataset er lille, kan et ensproget datasæt gøre en stor forskel.

Resultaterne viser, at ByteNet er i stand til at lære sprog oversættelse fra Tysk til Engelsk ved at bruge et tosproget dataset. Modellen var desvære for tidsmæssigt langsom til at kunne blive brugt i en semi-vejledt kontekst til sprog oversættelse. Variationer af ByteNet modellen var afprøvet for at reducere træningstiden, men ingen af disse modeller var succesfulde.

På grund af træningstidsproblemet blev en reduceret ByteNet model brugt til at lære et syntetisk problem, der mindre om naturlige sprog oversættelse. De semi-vejledte eksperimenter viste at ensproget data forbedre modellens ydeevne.
