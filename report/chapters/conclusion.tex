%!TEX root = ../Thesis.tex
\chapter{Conclusion}

Neural machine translation is a difficult and fast moving field. Over the 6 months this thesis has been carried out, several papers with new translation models have published. Each model shows a new state-of-the-part performance over the previous model on the WMT translation task \cite{bytenet, attention-is-all-you-need, tensor2tensor}. These models are created by Google, Microsoft, Facebook, etc., who have both computational resources and man-power to implement and experiment with a huge number of models. The goal and expectation of this thesis is thus not compete with these models, but rather explore a new direction for neural machine translation, by using additional monolingural (unlabeled) data. However, to do this a fast and decent translation model is required, thus much effort have been put into the supervised model.

\paragraph{ByteNet} The ByteNet model was able to learn both the synthetic digits problem and memorize the WMT NewsTest dataset, this confirms the implementation and capabilities of the ByteNet model. For the real problem where the Europarl v7 dataset is used, ByteNet managed to archive a BLEU score of $7.44$ and produce reasonable good translations. This is far from state-of-the-art or just a phase-based (PBMT) baseline model, however given the limited resources the results are rather good.

The original ByteNet paper including the latest revision, did not disclose how much time was spent training or how many resources that were used. From a scientific point of view this is rather inadequate, especially because they created the model from a computational performance perspective. A recent blog-post from Google published in June 2017, compares the different translation models and shows that ByteNet is actually one of the most computationally expensive models \cite{tensor2tensor}.

It is possible that if the oscillation issues were solved, if TensorFlow improving the execution speed with the XLA just-in-time (JIT) compiler \cite{google-xla}, and if CuDNN supported dilated convolution and normalization, that ByteNet could run in reasonable time. However, it will likely take at least a year before TensorFlow and CuDNN are at this state.

\paragraph{Simplified ByteNet} Because ByteNet takes too much time to train, a simplified version of ByteNet was created. Thus has 1/3 the layers and 5/9 the weight, while still maintaining the founding principals behind ByteNet and maintains the dimensional bottleneck. This was done by reducing the embedding dimensionality and removing the dimensional compression and decompression layers.

On the validation problems this performed identically or better compared to the normal ByteNet model. However, when trained on the Europarl v7 dataset the model showed severe overfitting and achieves a test BLEU score of only $0.55$. This indicates that the compression and decompression layers are somehow essential regularization components. In terms of time spend training, the simplified ByteNet model is only 20\% faster and converges correspondingly slower. Profiling the simplified ByteNet model, did unfortunately not reveal why the model is only 20\% faster, but did reveal that normalization is the primary bottleneck in terms of time spent.

The results indicates that simplifying ByteNet is not a direction worth exploring further, at least not for natural language translation. The approach might be valid for simpler problems, but for these problems there are likely completely different model architectures that are better suited.

\paragraph{SELU ByteNet} Identifying that normalization is the primary computational bottleneck, suggests that if these layers can somehow be removed the ByteNet model should perform significantly better. Training a non-normalized ByteNet model on even simple tasks converges very slowly. Recently a paper showed that a special activation called SELU (Self-normalizing Exponential Linear Unit) can be used as a replacement for the typical ReLU and normalization combination. By using the SELU activation as a replacement for ReLU and normalization, the ByteNet model model convergences on the simple tasks.

On the Europarl v7 dataset the SELU ByteNet model does not converge. This appears to be caused by exploding gradients. Such issues could be solved by gradient clipping. However, the purpose of SELU is precisely to prevent exploding and vanishing gradients issues, thus gradient clipping is likely not a good strategy.

In terms of computational performance the SELU ByteNet is much faster than both the normal ByteNet model and the simplified ByteNet model. On the Eurparl v7 problem the SELU ByteNet model runs 13 epochs in 18 hours, the normal ByteNet model uses 4 days on the same number of epochs. Profiling reveal that the time is primarily spent in the SELU activation function. This validates the known issue, where TensorFlow spends an unreasonably amount of time running simple element-wise operations \cite{google-xla}.

From a computational perspective, SELU ByteNet is promising, however as is, it is not suitable for learning translation on the Eurparl v7 dataset. If SELU ByteNet could be made to work, ByteNet would be a serious contender to other models in terms of computation time.

\paragraph{Semi-Supervised ByteNet} Without a suitable fast translation model, it is not feasible to run the semi-supervised ByteNet model on the Europarl v7 dataset. This is because the semi-supervised model depends on two translation models, each running on translations produced by a BeamSearch algorithm. Thus, one should expect the semi-supervised model to take 10 times longer to train. 

With the the computational demands of ByteNet in mind, the semi-supervised ByteNet model was used on a synthetic problem translating spelled-out digits to digit symbols. For example, ``one zero four'' is translated to ``104''. On this problem the semi-supervised ByteNet model showed improvement over both the supervised ByteNet model and an attention-based baseline model.

This validates the results from the original paper \cite{semi-supervised}, where the BELU score could be improved by $3.5$ to $1.5$. While such an improvement doesn't completely solve all issues, when training on language-pairs where the bilingual dataset is small, it could be an important component when the bilingual data isn't plentiful but the monolingural data is.

% While the semi-supervised model is not mathematically interesting, it is a pragmatic approach that works well with models that have fast/linear-time inference, such as ByteNet. However the ByteNet model is too slow for it to be relevant.

\paragraph{Future Works} With the resent results published by Google, showing that ByteNet is actually one of the slowest machine translation models \cite{tensor2tensor}, ByteNet is not a likely model for neural machine translation, and even less likely as a semi-supervised model. It is possible that the SELU ByteNet model could be tuned to work, in which case it might be compatible model. More time should be spent exporing the underlying cause and possible solutions to the exploding gradient issues in SELU ByteNet.

Recently a new paper showed that attention can be used instead of bi-directional RNN layers or hieratical-dilated-convolution. Using this approach they created a neural machine translation model that achieves a new state-of-the-art BLEU score on en-de translation. The model is also faster than many previous models, as it is shares many of the founding principals of ByteNet. That is, resolution persistent encoding, parallelization over the sequences, and training in linear time, are essential properties \cite{attention-is-all-you-need}.

Such a translation model is close to ideal, to be used in combination with the semi-supervised approach. Although, because the model is based on attention inference can't be done in linear time, unlike ByteNet, which may be essential for computing the unsupervised part of the loss-function. That being said, it is only the forward pass of one of the translation models that will run in quadratic time. The both backward passes and the other translation model will run in linear-time.

A different approach for making the semi-supervised model converge within reasonable time, is to initialize the weights with the learned weights from the two translation models it uses, where the translation models are pre-trained on a bilingual dataset. This would work as a pseudo-transfer learning, ``pseudo'' because the application domain is the same and it is the same models that are used. While this may improve convergence for a reasonable fast translation model, ByteNet is still too slow to be fully trained on just a single bilingual dataset.

Finally, one could look at a completely different approach for semi-supervised machine translation. In image processing adversarial networks have been successfully used to ``translate'' between for example a zebra and a horse, without paired training data \cite{gan-image-translation}. A similar approach could perhaps be used in the field of natural language translation. However, the current state of adversarial networks for natural languages is still far behind compared to other applications \cite{gan-on-nlp}.